{
  "hash": "58c3c9f962904715c6726266559fc3f6",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"\"\nsubtitle: \"\"\nauthor: \"\"\ntitle-slide-attributes:\n  data-background-image: \"\"\n  data-background-size: \"\"\n  data-background-opacity: \"\"\n  data-slide-number: true\nfooter: |\n  <div style=\"\n    position: relative;\n    bottom: 0;\n    left: 650px;\n    right: 0;\n    height: 50px;\n    background: rgba(255, 255, 255, 0.8);\n    display: flex;\n    align-items: center;\n    justify-content: space-between;\n    padding: 0 24px 0 40px;\n    box-sizing: border-box;\n  \">\n    <span style=\"font-size: 2em; padding-right: 200px;\">Wednesday-August-20-2025</span>\n    <img src=\"images/audio_chrome_5.png\" height=\"41\" style=\"vertical-align: middle;\" />\n  </div>  \nformat:\n  revealjs:\n    theme:  ['data/customtheming.scss']\n    css: slide_styles.css\n    slide-number: true\neditor: visual\njupyter: python3\nexecute:\n  echo: false\n---\n\n\n\n::: {.banner-container style=\"margin-bottom: 30px;\"}\n![](images/banner_mk2.png){.banner-image style=\"max-width: 100%; height: auto;\"}\n:::\n\n\n\n\n```{=html}\n<!-- Parent Container -->\n<div style=\"display: flex; justify-content: space-between; align-items: flex-start; width: 100%; padding: 40px; box-sizing: border-box;\">\n\n  <!-- LEFT column: Image + Audiophiles block -->\n  <div style=\"display: flex; flex-direction: column; align-items: flex-start; margin-right: 20px; transform: translate(-60px, -20px);\">\n    <!-- Image -->\n    <div style=\"margin-bottom: 10px; margin-left: 40px;\">\n      <img src=\"images/DS_group_mk5.png\" alt=\"Water Drop\" style=\"height: 300px;\" />\n    </div>\n    <!-- Audiophiles block -->\n    <div style=\"\n      display: flex;\n      align-items: center;\n      border: 1px solid black;\n      border-radius: 12px;\n      padding: 10px 16px;\n      background-color: #fff;\n      width: 380px;\n    \">\n      <img src=\"images/head_phones.png\" alt=\"Logo\" style=\"height: 120px; margin-right: 16px;\" />\n      <span style=\"\n        font-size: 22px;\n        font-family: Arial, sans-serif;\n        color: #333;\n      \">\n        <strong>The AudioPhiles:</strong><br> Nathan Herling<br> & Yashi Mi\n      </span>\n    </div>\n  </div>\n\n  <!-- RIGHT column: Title + course info -->\n  <div style=\"display: flex; flex-direction: column; justify-content: flex-start; height: 300px; text-align: right;\">\n    <!-- Title block -->\n    <div style=\"\n      font-size: 70px;\n      font-weight: bold;\n      font-family: Arial, sans-serif;\n      text-align: left;\n      line-height: 1.4;\n      color: #1B9FAB;\n      margin-bottom: 20px;\n    \">\n      Audio Alchemy:<br>\n      Decoding Sound for Smarter UX\n    </div>\n\n    <!-- INFO 523 block -->\n    <div style=\"\n      font-size: 30px;\n      color: #AB0520;\n      border: 3px solid #AB0520;\n      border-radius: 16px;\n      padding: 16px 24px;\n      background-color: #fff5f7;\n      box-shadow: 0 4px 10px rgba(171, 5, 32, 0.2);\n      display: inline-block;\n      margin-top: 0px;\n      width: 100%;\n    \">\n      INFO 523 ‚Äî Summer 2025 - Final Project\n    </div>\n  </div>\n\n</div>\n\n\n```\n\n\n\n\n\n<!--Slide 2 -->\n##\n\n\n\n```{=html}\n<div style=\"margin: -20px auto; border: 2px solid #ccc; border-radius: 10px; padding: 12px 20px; background-color: #fdfdfd; font-size: 0.60em; line-height: 1.3; max-width: 110%;\">\n\n  <h3 style=\"color:#007ACC; margin: 0 0 4px;\">üéØ Project Description & Goals</h3>\n  <p style=\"margin: 0 0 4px;\">Our team is developing a machine learning system for an AI-driven music recommendation service.<br>The main goals are:</p>\n  <ul style=\"margin: 0 0 4px 16px; padding-left: 0; list-style-position: outside;\">\n    <li style=\"margin: 0;\">Build a model capable of recognizing the language(s) spoken in audio files.</li>\n    <li style=\"margin: 0;\">Assess whether new songs align with a user‚Äôs musical preferences.</li>\n  </ul>\n\n  <hr style=\"margin: 6px 0; border: none; border-top: 1px solid #ddd;\">\n\n  <h3 style=\"color:#32CD32; margin: 0 0 4px;\">‚ùì Research Question 1 ‚Äì Language Recognition</h3>\n  <p style=\"margin: 0 0 4px;\"><strong>How can we leverage statistical and time-frequency features from separated vocal and audio tracks to build effective language recognition models?</strong></p>\n  <ul style=\"margin: 0 0 4px 16px; padding-left: 0; list-style-position: outside;\">\n    <li style=\"margin: 0;\">What are the strengths and limitations of classical models (e.g., SVMs, Random Forest, Logistic Regression)?</li>\n    <li style=\"margin: 0;\">How do feature engineering and validation improve model robustness?</li>\n  </ul>\n\n  <hr style=\"margin: 6px 0; border: none; border-top: 1px solid #ddd;\">\n\n  <h3 style=\"color:#32CD32; margin: 0 0 4px;\">‚ùì Research Question 2 ‚Äì Recommendation System [Genre Recognition]</h3>\n  <p style=\"margin: 0 0 4px;\"><strong>Starting with genre recognition as part of the user UI/UX, can a user‚Äôs preferred genres be learned through feature analysis of audio files?</strong></p>\n  <ul style=\"margin: 0 0 0 16px; padding-left: 0; list-style-position: outside;\">\n    <li style=\"margin: 0;\">Using classical supervised models: Can audio features be extracted and models trained to recognize a user's preferred genres?</li>\n    <li style=\"margin: 0;\">Using frequency/time heatmap image extraction: Are classical models capable of determining musical genres?</li>\n  </ul>\n\n</div>\n```\n\n\n\n\n\n\n<!--Slide 3-->\n##\n\n\n\n```{=html}\n<div style=\"font-family: Arial, sans-serif; font-size: 0.75em; line-height: 1.4; width: 100%; margin: -10px auto 20px auto; padding: 16px; border: 1.5px solid #ccc; border-radius: 8px; background-color: #f9f9f9;\">\n  <h3 style=\"color: #007ACC; margin-bottom: 12px; text-align: center;\">Data Files and Extraction Workflow</h3>\n  <ul style=\"padding-left: 20px; color: #333; margin: 0;\">\n    <li><strong>User Input:</strong> Initial CSV files containing song names; optionally including genre, language, and artist information.</li>\n    <li><strong>Data Completion:</strong> Automated web scraping to fill missing metadata fields such as genre, language, and artist.</li>\n    <li><strong>YouTube Integration:</strong> Web scraping YouTube to find matching song links, then storing these links and related metadata in a JSON file.</li>\n    <li><strong>Audio Acquisition:</strong> Downloading .wav audio files from YouTube links for each song.</li>\n    <li><strong>Feature Extraction:</strong> Using Python scripts to analyze audio files and extract features (e.g., fundamental frequency, MFCCs, tempo).</li>\n    <li><strong>Output Files:</strong> Extracted audio features are saved into CSV files; visualizations like spectrograms are saved as PNG images.</li>\n  </ul>\n</div>\n```\n\n\n\n\n<!--Slide 4 -->\n##\n::: {.cell}\n<div style=\"max-width: 100%; margin: 0 -80px 0 -80px; font-family: Arial, sans-serif; font-size: 0.65em; line-height: 1.2; border: 1.5px solid #ccc; border-radius: 8px; padding: 8px 12px; background-color: #fdfdfd; overflow-x: auto;\">\n\n  <h2 style=\"color: #007ACC; margin: 0 0 8px 0; text-align: center; font-size: 1.2em;\">Feature Scraping</h2>\n\n  <table style=\"width: 100%; border-collapse: collapse; table-layout: fixed; word-wrap: break-word;\">\n    <thead>\n      <tr style=\"background-color: #007ACC; color: white; text-align: left;\">\n        <th style=\"width: 25%; padding: 4px 8px; border: 1px solid #ccc;\">Feature</th>\n        <th style=\"width: 75%; padding: 4px 8px; border: 1px solid #ccc;\">Description</th>\n      </tr>\n    </thead>\n    <tbody>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">fundamental_freq</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Fundamental frequency (mean pitch via librosa.pyin)</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">freq_e_1</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Dominant spectral energy #1 (highest energy frequency bin)</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">freq_e_2</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Dominant spectral energy #2 (2nd highest energy frequency bin)</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">freq_e_3</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Dominant spectral energy #3 (3rd highest energy frequency bin)</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">key</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Estimated musical key (C, C#, D, ..., B) via chroma features</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">duration</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Length of audio in seconds</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">zero_crossing_rate</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Average zero crossing rate (signal sign changes)</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">mfcc_mean</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Mean of 13 MFCC coefficients (timbre features)</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">mfcc_std</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Standard deviation of MFCC coefficients</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">tempo</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Estimated tempo in beats per minute (BPM)</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">rms_energy</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Root mean square energy (loudness measure)</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">track_type</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Audio track type (0=full mix, 1=vocal only, 2=no vocals)</td></tr>\n      <tr><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">mel_spectrogram</td><td style=\"padding: 4px 8px; border: 1px solid #ccc;\">Mel-scaled spectrogram representing frequency content over time (human hearing range)</td></tr>\n    </tbody>\n  </table>\n</div>\n:::\n\n\n\n\n\n<!--Slide 5 -->\n##\nQ1 Overview - Yashi describe your quetion and how you implemented mL [libraries, validation]\n\n<!--Slide 6 -->\n##\nQ1 Results [1/3] - Yashi graphs? Learning Curve, ROC, any hyperparameter optimization?\n\n<!--Slide 7 -->\n##\nQ1 Results [2/3] - Yashi. Results (% scores)\n\n<!--Slide 8 -->\n##\nQ1 Summary [3/3] - Summarize\n\n<!--Slide 9 -->\n##\nQ2 Overview\n\n<!--Slide 10 -->\n##\nQ2 Results [1/3]\n\n<!--Slide 11 -->\n##\nQ2 Results [2/3]\n\n<!--Slide 12 -->\n##\nQ2 Results [3/3]\n\n<!--Slide 13 -->\n##\nQ2 Summary\n\n<!--Slide 14 -->\n##\nFull Summary\n\n<!--Slide 15 -->\n##\nIn Closing\n\n",
    "supporting": [
      "presentation_files"
    ],
    "filters": [],
    "includes": {}
  }
}