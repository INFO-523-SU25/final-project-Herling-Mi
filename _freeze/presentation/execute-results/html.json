{
  "hash": "762e2dc093f3e776faff466dbd3d28ab",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"\"\nsubtitle: \"\"\nauthor: \"\"\ntitle-slide-attributes:\n  data-background-image: \"\"\n  data-background-size: \"\"\n  data-background-opacity: \"\"\n  data-slide-number: true\nfooter: |\n  <div style=\"\n    position: relative;\n    bottom: -10px;\n    left: 650px;\n    right: 0;\n    height: 50px;\n    background: rgba(255, 255, 255, 0.8);\n    display: flex;\n    align-items: center;\n    justify-content: space-between;\n    padding: 0 24px 0 40px;\n    z-index: 9999;\n    box-sizing: border-box;\n    margin-top: 200px; /* adjust to push it further down */\n  \">   \n    <span style=\"position: relative; font-size: 2em; padding-right: 500px;margin-top: -30px\">Wednesday-August-20-2025</span>\n    <img src=\"images/audio_chrome_5.png\" height=\"80\" style=\"vertical-align: middle;margin-top: -10px;\" />\n  </div>  \nformat:\n  revealjs:\n    theme:  ['data/customtheming.scss']\n    css: slide_styles.css\n    slide-number: true\neditor: visual\njupyter: python3\nexecute:\n  echo: false\n---\n\n\n\n::: {.banner-container style=\"margin-bottom: 30px; margin-left: -130px;\"}\n![](images/banner_mk2.png){.banner-image style=\"max-width: 100%; height: auto;\"}\n:::\n\n\n```{=html}\n<!-- Parent Container -->\n<div style=\"display: flex; justify-content: space-between; align-items: flex-start; width: 100%; padding: 40px; box-sizing: border-box;\">\n\n  <!-- LEFT column: Image + Audiophiles block -->\n  <div style=\"display: flex; flex-direction: column; align-items: flex-start; margin-right: 20px; transform: translate(-60px, -20px);\">\n    <!-- Image -->\n    <div style=\"margin-bottom: 10px; margin-left: 40px;\">\n      <img src=\"images/DS_group_mk5.png\" alt=\"Water Drop\" style=\"height: 300px;\" />\n    </div>\n    <!-- Audiophiles block -->\n    <div style=\"\n      display: flex;\n      align-items: center;\n      border: 1px solid white;\n      border-radius: 12px;\n      padding: 10px 10px;\n      background-color: #fff;\n      width: 380px;\n    \">\n      <img src=\"images/audio_phile_logo_mk2.png\" alt=\"Logo\" style=\"height: 160px; margin-right: 0px;\" />\n    </div>\n  </div>\n\n  <!-- RIGHT column: Title + course info -->\n  <div style=\"display: flex; flex-direction: column; justify-content: flex-start; height: 300px; text-align: right;\">\n    <!-- Title block -->\n    <div style=\"\n      font-size: 70px;\n      font-weight: bold;\n      font-family: Arial, sans-serif;\n      text-align: left;\n      line-height: 1.4;\n      color: #1B9FAB;\n      margin-bottom: 20px;\n    \">\n      Audio Alchemy:<br>\n      Decoding Sound for Smarter UX\n    </div>\n\n    <!-- INFO 523 block -->\n    <div style=\"\n      font-size: 30px;\n      color: #AB0520;\n      border: 3px solid #AB0520;\n      border-radius: 16px;\n      padding: 16px 24px;\n      background-color: #fff5f7;\n      box-shadow: 0 4px 10px rgba(171, 5, 32, 0.2);\n      display: inline-block;\n      margin-top: 0px;\n      width: 100%;\n    \">\n      INFO 523 ‚Äî Summer 2025 - Final Project\n    </div>\n  </div>\n\n</div>\n```\n\n\n<!--Slide 2 -->\n\n## \n\n\n```{=html}\n<div style=\"margin: -20px -60px -80px -80px; border: 5px solid midnightblue; border-radius: 10px; padding: 12px 20px; background-color: #fdfdfd; font-size: 0.60em; line-height: 1.3; width: 110%;\">\n\n\n  <h3 style=\"color:#007ACC; margin: 0 0 4px;\">ü§ñ Project Description & Goals</h3>\n<p style=\"margin: 0 0 4px; font-weight: bold;\">\n  Our team is developing a machine learning system for an AI-driven music recommendation service.<br>\n  The main goals are:\n</p>\n  <ul style=\"margin: 0 0 4px 16px; padding-left: 0; list-style-position: outside;\">\n    <li style=\"margin: 0;\">Build a model capable of recognizing the language(s) spoken in audio files.</li>\n    <li style=\"margin: 0;\">Assess whether new songs align with a user‚Äôs musical preferences.</li>\n  </ul>\n\n  <hr style=\"margin: 6px 0; border: none; border-top: 2px solid #aaa;\">\n\n  <h3 style=\"color:#32CD32; margin: 0 0 4px;\">‚ú¶ Question 1 ‚Äì Language Recognition</h3>\n  <p style=\"margin: 0 0 4px;font-weight: bold;\"><strong>How can we leverage statistical and time-frequency features from separated vocal and audio tracks to build effective language recognition models?</strong></p>\n  <ul style=\"margin: 0 0 4px 16px; padding-left: 0; list-style-position: outside;\">\n    <li style=\"margin: 0;\">What are the strengths and limitations of classical models (e.g., SVMs, Random Forest, Logistic Regression)?</li>\n    <li style=\"margin: 0;\">How do feature engineering and validation improve model robustness?</li>\n  </ul>\n\n  <hr style=\"margin: 6px 0; border: none; border-top: 2px solid #aaa;\">\n\n  <h3 style=\"color:#32CD32; margin: 0 0 4px;\">‚ú¶ Question 2 ‚Äì Recommendation System [Genre Recognition]</h3>\n  <p style=\"margin: 0 0 4px;font-weight: bold;\"><strong>Starting with genre recognition as part of the user UI/UX, can a user‚Äôs preferred genres be learned through feature analysis of audio files?</strong></p>\n  <ul style=\"margin: 0 0 0 16px; padding-left: 0; list-style-position: outside;\">\n    <li style=\"margin: 0;\">Using classical supervised models: Can audio features be extracted and models trained to recognize a user's preferred genres?</li>\n    <li style=\"margin: 0;\">Using frequency/time heatmap image extraction: Are classical models capable of determining musical genres from spectrogram-like representations?</li>\n  </ul>\n\n</div>\n```\n\n\n<!--Slide 3-->\n\n## \n\n\n```{=html}\n<div style=\"margin: -20px -60px -80px -80px; border: 5px solid midnightblue; border-radius: 10px; padding: 12px 20px; background-color: #fdfdfd; font-size: 0.75em; line-height: 1.3; width: 110%;\">\n\n  <h3 style=\"color: #007ACC; margin-bottom: 12px; text-align: center;\">üß© Data Files and Extraction Workflow</h3>\n  <ul style=\"padding-left: 20px; color: #333; margin: 0;\">\n    <li><strong>User Input:</strong> Providing initial <code>CSV</code> files containing song names, optionally including genre, language, and artist information.</li>\n    <li><strong>Data Completion:</strong> Performing automated web scraping with <code>Python</code> scripts, filling in missing metadata fields such as genre, language, and artist.</li>\n    <li><strong>YouTube Integration:</strong> Scraping YouTube with <code>Python</code> scripts, finding matching song <code>URLs</code>, and storing these links and related metadata in a <code>JSON</code> file.</li>\n    <li><strong>Audio Acquisition:</strong> Downloading <code>.wav</code> audio files from YouTube <code>URLs</code> for each song with <code>Python</code> scripts.</li>\n    <li><strong>Feature Extraction:</strong> Using <code>Python</code> (<code>numpy</code> and <code>librosa</code> libraries) scripts for analyzing audio files and extracting features (e.g., fundamental frequency, MFCCs, tempo).</li>\n    <li><strong>Output Files:</strong> Saving extracted audio features as <code>CSV</code> files; saving visualizations such as spectrograms as <code>.png</code> images. From here, constructing machine learning pipelines with <code>Python</code> libraries.</li>\n  </ul>\n</div>\n```\n\n\n<!--Slide 4 -->\n\n## \n\n:::: cell\n::: {style=\"width: 125%; margin: -40px -140px 30px -160px; font-family: Arial, sans-serif; font-size: 0.65em; line-height: 1.2; border: 5px solid midnightblue; border-radius: 8px; padding: 8px 12px; background-color: #fdfdfd; overflow-x: auto;\"}\n<h2 style=\"color: #007ACC; margin: -10px 0 -10px 0; text-align: center; font-size: 2.0em;\">\n\nüîç Feature Scraping\n\n</h2>\n\n| Feature | Description |\n|-----------------|-------------------------------------------------------|\n| fundamental_freq | Fundamental frequency (mean pitch via librosa.pyin) |\n| freq_e_1 | Dominant spectral energy #1 (highest energy frequency bin) |\n| freq_e_2 | Dominant spectral energy #2 (2nd highest energy frequency bin) |\n| freq_e_3 | Dominant spectral energy #3 (3rd highest energy frequency bin) |\n| key | Estimated musical key (C, C#, D, ..., B) via chroma features |\n| duration | Length of audio in seconds |\n| zero_crossing_rate | Average zero crossing rate (signal sign changes) |\n| mfcc_mean | Mean of 13 MFCC coefficients (timbre features) |\n| mfcc_std | Standard deviation of MFCC coefficients |\n| tempo | Estimated tempo in beats per minute (BPM) |\n| rms_energy | Root mean square energy (loudness measure) |\n| track_type | Audio track type (0=full mix, 1=vocal only, 2=no vocals) |\n| mel_spectrogram | Mel-scaled spectrogram representing frequency content over time (human hearing range) |\n:::\n::::\n\n------------------------------------------------------------------------\n\n<!--Slide 5 -->\n\n\n```{=html}\n<div>\n  <div style=\"text-align: center; margin-bottom: 16px;\">\n    <h4>üìä <strong>Research Question 1 ‚Äì Language Recognition</strong></h4>\n  </div>\n\n  <div style=\"font-size: 30px; line-height: 1.4;\">\n    <ul>\n      <li><strong>Goal</strong>: Classify songs by <strong>language</strong> using audio-derived numerical features.</li>\n      <li><strong>Dataset</strong>: Extracted features from ~120 tracks, annotated with artist, country, language, and track type.</li>\n      <li><strong>Preprocessing</strong>:\n        <ul>\n          <li>Standardized all numeric features.</li>\n          <li>Encoded target variable (language) with LabelEncoder.</li>\n        </ul>\n      </li>\n      <li><strong>Validation</strong>:\n        <ul>\n          <li>Applied <strong>Stratified K-Fold (k=5)</strong> cross-validation.</li>\n          <li>Used multiple metrics: Accuracy, Precision, Recall, and F1-score.</li>\n        </ul>\n      </li>\n      <li><strong>Models</strong>: Logistic Regression, Random Forest, and Linear SVM.</li>\n    </ul>\n  </div>\n</div>\n```\n\n\n------------------------------------------------------------------------\n\n<!--Slide 6 -->\n\n::: {style=\"text-align: center; margin-bottom: 12px;\"}\n<h4>Evaluation Results</h4>\n:::\n\n:::: cell\n::: {style=\"width: 120%; margin: 20px -140px 30px -120px; font-family: Arial, sans-serif; font-size: 0.65em; line-height: 1.2; border: 2px solid midnightblue; border-radius: 8px; padding: 8px 12px; background-color: #fdfdfd; overflow-x: auto;\"}\n<h2 style=\"color: #007ACC; margin: 0 0 8px 0; text-align: center; font-size: 1.2em;\">\n\nModel Performance ‚Äì Ablation Study\n\n</h2>\n\n| Ablation       | Model        | Accuracy | Precision | Recall | F1    |\n|----------------|--------------|----------|-----------|--------|-------|\n| complete_song  | LogReg       | 0.399    | 0.398     | 0.447  | 0.387 |\n| complete_song  | RandomForest | 0.626    | 0.469     | 0.410  | 0.401 |\n| complete_song  | SVM_linear   | 0.432    | 0.443     | 0.504  | 0.427 |\n| vocal_only     | LogReg       | 0.560    | 0.531     | 0.567  | 0.509 |\n| vocal_only     | RandomForest | 0.552    | 0.426     | 0.404  | 0.385 |\n| vocal_only     | SVM_linear   | 0.544    | 0.542     | 0.583  | 0.514 |\n| no_vocal       | LogReg       | 0.333    | 0.371     | 0.364  | 0.316 |\n| no_vocal       | RandomForest | 0.577    | 0.436     | 0.349  | 0.328 |\n| no_vocal       | SVM_linear   | 0.366    | 0.418     | 0.411  | 0.347 |\n| **Column Min** | \\-           | 0.333    | 0.371     | 0.349  | 0.316 |\n| **Column Max** | \\-           | 0.626    | 0.542     | 0.583  | 0.514 |\n:::\n::::\n\n## <!--Slide 7 -->\n\n::: {style=\"text-align: center; margin-top: -40px; margin-right: 10px; margin-bottom: 30px; margin-left: 5px;\"}\n<h4>F1 (macro) comparison across ablations and models</h4>\n:::\n\n::: {#274cedf0 .cell fig-format='svg' fig-height='4' fig-width='7' execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](presentation_files/figure-revealjs/cell-4-output-1.png){fig-align='center'}\n:::\n:::\n\n\n<!--Slide 8 -->\n\n## üìå Question 1-Summary\n\n\n```{=html}\n<div style=\"font-size: 30px; line-height: 1.4;\">\n  <ul>\n    <li><strong>What we did</strong>:\n      <ul>\n        <li>Designed a supervised ML pipeline with feature scaling, label encoding, stratified CV.</li>\n        <li>Evaluated three classifiers on different track-type subsets.</li>\n      </ul>\n    </li>\n    <li><strong>Results</strong>:\n      <ul>\n        <li>Best model = <strong>Linear SVM</strong> trained on <strong>vocal_only</strong> data.</li>\n        <li>Achieved ~50% performance across all metrics.</li>\n      </ul>\n    </li>\n    <li><strong>Conclusion</strong>:\n      <ul>\n        <li>Vocal features are sufficient to classify language with strong accuracy.</li>\n        <li>Next: expand dataset, apply hyperparameter optimization, and test on external songs.</li>\n      </ul>\n    </li>\n  </ul>\n</div>\n```\n\n\n<!--Slide 9 -->\n\n## \n\nQ2 (A/B) Overview - Nathan describe your question and how you implemented mL \\[libraries, validation\\]\n\n<!--Slide 10 -->\n\n## \n\nQ2 (A) Results - Nathan graphs? Learning Curve, ROC, any hyperparameter optimization?\n\n<!--Slide 11 -->\n\n## \n\nQ2 (A) Results - Nathan Results (% scores) Validation methods.\n\n<!--Slide 12 -->\n\n## \n\nQ2 (B) Results - Nathan. Summarize - what you did/results.\n\n<!--Slide 13 -->\n\n## \n\nQ2 (B) Results \\[3/3\\] - Nathan. Summarize - what you did/results.\n\n<!--Slide 14 -->\n\n## \n\nQ2 Summary - Nathan\n\n<!--Slide 15 -->\n\n## \n\nFull Summary - Nathan talk about both question findings.\n\n<!--Slide 16 -->\n\n## \n\n::: {.banner-container style=\"margin-bottom: 30px; margin-left: -130px;\"}\n![](images/banner_mk2.png){.banner-image style=\"max-width: 100%; height: auto;\"}\n:::\n\n<!-- Parent container -->\n\n\n```{=html}\n<div style=\"\n    display: flex;\n    justify-content: space-between;\n    align-items: center; /* vertical center for right image */\n    width: 100%;\n    height: 500px; /* adjust height as needed */\n    position: relative;\n    padding: 40px;\n    box-sizing: border-box;\n    margin-left: -40px;\n\">\n\n  <!-- LEFT column: top text + bottom logo -->\n  <div style=\"display: flex; flex-direction: column; justify-content: space-between; height: 100%;\">\n    \n    <!-- TOP LEFT: Text block -->\n    <div style=\"text-align: left;\">\n      <h3>Thank you for listening</h3>\n      <ul style=\"font-size: 35px; margin-top: 20px;\">\n        <li>Your attention was appreciated.</li>\n        <li>Questions welcome.</li>\n      </ul>\n      <p>Team Members:</p>\n    </div>\n\n    <!-- BOTTOM LEFT: Logo -->\n    <div style=\"\n        display: inline-block;\n        padding: 4px;\n        margin-top: -30px;\n        margin-right: 150px;\n        margin-left: -50px;\n    \">\n      <img src=\"images/audio_phile_logo_mk2.png\" alt=\"AudioPhile Logo\" style=\"height: 180px;\">\n    </div>\n    \n  </div>\n\n  <!-- RIGHT column: vertical-centered GIF -->\n  <div style=\"display: flex; align-items: center;margin-left: 10px;margin-right: -80px\">\n    <img src=\"images/rotating_cube_signal_4.gif\" alt=\"Rotating Cube\" style=\"height: 300px;\">\n  </div>\n\n</div>\n```\n\n",
    "supporting": [
      "presentation_files\\figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}