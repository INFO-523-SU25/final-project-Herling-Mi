---
title: ""
subtitle: ""
author: ""
title-slide-attributes:
  data-background-image: ""
  data-background-size: ""
  data-background-opacity: ""
  data-slide-number: true
footer: |
  <div style="
    position: relative;
    bottom: -10px;
    left: 650px;
    right: 0;
    height: 50px;
    background: rgba(255, 255, 255, 0.8);
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 0 24px 0 40px;
    z-index: 9999;
    box-sizing: border-box;
    margin-top: 200px; /* adjust to push it further down */
  ">   
    <span style="position: relative; font-size: 2em; padding-right: 500px;margin-top: -30px">Wednesday-August-20-2025</span>
    <img src="images/audio_chrome_5.png" height="80" style="vertical-align: middle;margin-top: -10px;" />
  </div>  
format:
  revealjs:
    theme:  ['data/customtheming.scss']
    css: slide_styles.css
    slide-number: true
editor: visual
jupyter: python3
execute:
  echo: false
---

```{python}
#| label: load-packages
#| include: false

# Load packages here
import pandas as pd
import seaborn as sns

```

```{python}
#| label: setup
#| include: false
#| 
# Set up plot theme and figure resolution
sns.set_theme(style="whitegrid")
sns.set_context("notebook", font_scale=1.1)

import matplotlib.pyplot as plt
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['figure.figsize'] = (6, 6 * 0.618)
```

::: {.banner-container style="margin-bottom: 30px; margin-left: -130px;"}
![](images/banner_mk2.png){.banner-image style="max-width: 100%; height: auto;"}
:::

```{=html}
<!-- Parent Container -->
<div style="display: flex; justify-content: space-between; align-items: flex-start; width: 100%; padding: 40px; box-sizing: border-box;">

  <!-- LEFT column: Image + Audiophiles block -->
  <div style="display: flex; flex-direction: column; align-items: flex-start; margin-right: 20px; transform: translate(-60px, -20px);">
    <!-- Image -->
    <div style="margin-bottom: 10px; margin-left: 40px;">
      <img src="images/DS_group_mk5.png" alt="Water Drop" style="height: 300px;" />
    </div>
    <!-- Audiophiles block -->
    <div style="
      display: flex;
      align-items: center;
      border: 1px solid white;
      border-radius: 12px;
      padding: 10px 10px;
      background-color: #fff;
      width: 380px;
    ">
      <img src="images/audio_phile_logo_mk2.png" alt="Logo" style="height: 160px; margin-right: 0px;" />
    </div>
  </div>

  <!-- RIGHT column: Title + course info -->
  <div style="display: flex; flex-direction: column; justify-content: flex-start; height: 300px; text-align: right;">
    <!-- Title block -->
    <div style="
      font-size: 70px;
      font-weight: bold;
      font-family: Arial, sans-serif;
      text-align: left;
      line-height: 1.4;
      color: #1B9FAB;
      margin-bottom: 20px;
    ">
      Audio Alchemy:<br>
      Decoding Sound for Smarter UX
    </div>

    <!-- INFO 523 block -->
    <div style="
      font-size: 30px;
      color: #AB0520;
      border: 3px solid #AB0520;
      border-radius: 16px;
      padding: 16px 24px;
      background-color: #fff5f7;
      box-shadow: 0 4px 10px rgba(171, 5, 32, 0.2);
      display: inline-block;
      margin-top: 0px;
      width: 100%;
    ">
      INFO 523 ‚Äî Summer 2025 - Final Project
    </div>
  </div>

</div>
```

<!--Slide 2 -->

## 

```{=html}
<div style="margin: -20px -60px -80px -80px; border: 5px solid midnightblue; border-radius: 10px; padding: 12px 20px; background-color: #fdfdfd; font-size: 0.60em; line-height: 1.3; width: 110%;">


  <h3 style="color:#007ACC; margin: 0 0 4px;">ü§ñ Project Description & Goals</h3>
<p style="margin: 0 0 4px; font-weight: bold;">
  Our team is developing a machine learning system for an AI-driven music recommendation service.<br>
  The main goals are:
</p>
  <ul style="margin: 0 0 4px 16px; padding-left: 0; list-style-position: outside;">
    <li style="margin: 0;">Build a model capable of recognizing the language(s) spoken in audio files.</li>
    <li style="margin: 0;">Assess whether new songs align with a user‚Äôs musical preferences.</li>
  </ul>

  <hr style="margin: 6px 0; border: none; border-top: 2px solid #aaa;">

  <h3 style="color:#32CD32; margin: 0 0 4px;">‚ú¶ Question 1 ‚Äì Language Recognition</h3>
  <p style="margin: 0 0 4px;font-weight: bold;"><strong>How can we leverage statistical and time-frequency features from separated vocal and audio tracks to build effective language recognition models?</strong></p>
  <ul style="margin: 0 0 4px 16px; padding-left: 0; list-style-position: outside;">
    <li style="margin: 0;">What are the strengths and limitations of classical models (e.g., SVMs, Random Forest, Logistic Regression)?</li>
    <li style="margin: 0;">How do feature engineering and validation improve model robustness?</li>
  </ul>

  <hr style="margin: 6px 0; border: none; border-top: 2px solid #aaa;">

  <h3 style="color:#32CD32; margin: 0 0 4px;">‚ú¶ Question 2 ‚Äì Recommendation System [Genre Recognition]</h3>
  <p style="margin: 0 0 4px;font-weight: bold;"><strong>Starting with genre recognition as part of the user UI/UX, can a user‚Äôs preferred genres be learned through feature analysis of audio files?</strong></p>
  <ul style="margin: 0 0 0 16px; padding-left: 0; list-style-position: outside;">
    <li style="margin: 0;">Using classical supervised models: Can audio features be extracted and models trained to recognize a user's preferred genres?</li>
    <li style="margin: 0;">Using frequency/time heatmap image extraction: Are classical models capable of determining musical genres from spectrogram-like representations?</li>
  </ul>

</div>
```

<!--Slide 3-->

## 

```{=html}
<div style="margin: -20px -60px -80px -80px; border: 5px solid midnightblue; border-radius: 10px; padding: 12px 20px; background-color: #fdfdfd; font-size: 0.75em; line-height: 1.3; width: 110%;">

  <h3 style="color: #007ACC; margin-bottom: 12px; text-align: center;">üß© Data Files and Extraction Workflow</h3>
  <ul style="padding-left: 20px; color: #333; margin: 0;">
    <li><strong>User Input:</strong> Providing initial <code>CSV</code> files containing song names, optionally including genre, language, and artist information.</li>
    <li><strong>Data Completion:</strong> Performing automated web scraping with <code>Python</code> scripts, filling in missing metadata fields such as genre, language, and artist.</li>
    <li><strong>YouTube Integration:</strong> Scraping YouTube with <code>Python</code> scripts, finding matching song <code>URLs</code>, and storing these links and related metadata in a <code>JSON</code> file.</li>
    <li><strong>Audio Acquisition:</strong> Downloading <code>.wav</code> audio files from YouTube <code>URLs</code> for each song with <code>Python</code> scripts.</li>
    <li><strong>Feature Extraction:</strong> Using <code>Python</code> (<code>numpy</code> and <code>librosa</code> libraries) scripts for analyzing audio files and extracting features (e.g., fundamental frequency, MFCCs, tempo).</li>
    <li><strong>Output Files:</strong> Saving extracted audio features as <code>CSV</code> files; saving visualizations such as spectrograms as <code>.png</code> images. From here, constructing machine learning pipelines with <code>Python</code> libraries.</li>
  </ul>
</div>
```

<!--Slide 4 -->

## 

:::: cell
::: {style="width: 125%; margin: -40px -140px 30px -160px; font-family: Arial, sans-serif; font-size: 0.65em; line-height: 1.2; border: 5px solid midnightblue; border-radius: 8px; padding: 8px 12px; background-color: #fdfdfd; overflow-x: auto;"}
<h2 style="color: #007ACC; margin: -10px 0 -10px 0; text-align: center; font-size: 2.0em;">

üîç Feature Scraping

</h2>

| Feature | Description |
|-----------------|-------------------------------------------------------|
| fundamental_freq | Fundamental frequency (mean pitch via librosa.pyin) |
| freq_e_1 | Dominant spectral energy #1 (highest energy frequency bin) |
| freq_e_2 | Dominant spectral energy #2 (2nd highest energy frequency bin) |
| freq_e_3 | Dominant spectral energy #3 (3rd highest energy frequency bin) |
| key | Estimated musical key (C, C#, D, ..., B) via chroma features |
| duration | Length of audio in seconds |
| zero_crossing_rate | Average zero crossing rate (signal sign changes) |
| mfcc_mean | Mean of 13 MFCC coefficients (timbre features) |
| mfcc_std | Standard deviation of MFCC coefficients |
| tempo | Estimated tempo in beats per minute (BPM) |
| rms_energy | Root mean square energy (loudness measure) |
| track_type | Audio track type (0=full mix, 1=vocal only, 2=no vocals) |
| mel_spectrogram | Mel-scaled spectrogram representing frequency content over time (human hearing range) |
:::
::::

------------------------------------------------------------------------

<!--Slide 5 -->

```{=html}
<div>
  <div style="text-align: center; margin-bottom: 16px;">
    <h4>üìä <strong>Research Question 1 ‚Äì Language Recognition</strong></h4>
  </div>

  <div style="font-size: 30px; line-height: 1.4;">
    <ul>
      <li><strong>Goal</strong>: Classify songs by <strong>language</strong> using audio-derived numerical features.</li>
      <li><strong>Dataset</strong>: Extracted features from ~120 tracks, annotated with artist, country, language, and track type.</li>
      <li><strong>Preprocessing</strong>:
        <ul>
          <li>Standardized all numeric features.</li>
          <li>Encoded target variable (language) with LabelEncoder.</li>
        </ul>
      </li>
      <li><strong>Validation</strong>:
        <ul>
          <li>Applied <strong>Stratified K-Fold (k=5)</strong> cross-validation.</li>
          <li>Used multiple metrics: Accuracy, Precision, Recall, and F1-score.</li>
        </ul>
      </li>
      <li><strong>Models</strong>: Logistic Regression, Random Forest, and Linear SVM.</li>
    </ul>
  </div>
</div>
```

------------------------------------------------------------------------

<!--Slide 6 -->

::: {style="text-align: center; margin-bottom: 12px;"}
<h4>Evaluation Results</h4>
:::

:::: cell
::: {style="width: 120%; margin: 20px -140px 30px -120px; font-family: Arial, sans-serif; font-size: 0.65em; line-height: 1.2; border: 2px solid midnightblue; border-radius: 8px; padding: 8px 12px; background-color: #fdfdfd; overflow-x: auto;"}
<h2 style="color: #007ACC; margin: 0 0 8px 0; text-align: center; font-size: 1.2em;">

Model Performance ‚Äì Ablation Study

</h2>

| Ablation       | Model        | Accuracy | Precision | Recall | F1    |
|----------------|--------------|----------|-----------|--------|-------|
| complete_song  | LogReg       | 0.399    | 0.398     | 0.447  | 0.387 |
| complete_song  | RandomForest | 0.626    | 0.469     | 0.410  | 0.401 |
| complete_song  | SVM_linear   | 0.432    | 0.443     | 0.504  | 0.427 |
| vocal_only     | LogReg       | 0.560    | 0.531     | 0.567  | 0.509 |
| vocal_only     | RandomForest | 0.552    | 0.426     | 0.404  | 0.385 |
| vocal_only     | SVM_linear   | 0.544    | 0.542     | 0.583  | 0.514 |
| no_vocal       | LogReg       | 0.333    | 0.371     | 0.364  | 0.316 |
| no_vocal       | RandomForest | 0.577    | 0.436     | 0.349  | 0.328 |
| no_vocal       | SVM_linear   | 0.366    | 0.418     | 0.411  | 0.347 |
| **Column Min** | \-           | 0.333    | 0.371     | 0.349  | 0.316 |
| **Column Max** | \-           | 0.626    | 0.542     | 0.583  | 0.514 |
:::
::::

## <!--Slide 7 -->

::: {style="text-align: center; margin-top: -40px; margin-right: 10px; margin-bottom: 30px; margin-left: 5px;"}
<h4>F1 (macro) comparison across ablations and models</h4>
:::

```{python}
#| echo: false
#| fig-cap: ""
#| fig-width: 7
#| fig-height: 4
#| out-width: 70%
#| fig-align: center
#| fig-format: svg

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
data = [ {"ablation": "complete_song", "model": "LogReg", "f1": 0.387},
{"ablation": "complete_song", "model": "RandomForest", "f1": 0.401},
{"ablation": "complete_song", "model": "SVM_linear", "f1": 0.427},
{"ablation": "vocal_only", "model": "LogReg", "f1": 0.509},
{"ablation": "vocal_only", "model": "RandomForest", "f1": 0.385},
{"ablation": "vocal_only", "model": "SVM_linear", "f1": 0.514},
{"ablation": "no_vocal", "model": "LogReg", "f1": 0.316},
{"ablation": "no_vocal", "model": "RandomForest", "f1": 0.328},
{"ablation": "no_vocal", "model": "SVM_linear", "f1": 0.347}]
df_f1 = pd.DataFrame(data)
order_ablation = ["vocal_only", "complete_song", "no_vocal"]
order_model = ["SVM_linear", "LogReg", "RandomForest"]
df_f1["ablation"] = pd.Categorical(df_f1["ablation"], categories=order_ablation, ordered=True)
df_f1["model"] = pd.Categorical(df_f1["model"], categories=order_model, ordered=True)
plt.figure(figsize=(8,4))
ax = sns.barplot(data=df_f1, x="ablation", y="f1", hue="model")
ax.set_xlabel("Track Type (Ablation)")
ax.set_ylabel("F1 (macro)")
ax.set_title("F1 (macro) by Track Type and Model")
plt.show()
```

<!--Slide 8 -->

## üìå Question 1-Summary

```{=html}
<div style="font-size: 30px; line-height: 1.4;">
  <ul>
    <li><strong>What we did</strong>:
      <ul>
        <li>Designed a supervised ML pipeline with feature scaling, label encoding, stratified CV.</li>
        <li>Evaluated three classifiers on different track-type subsets.</li>
      </ul>
    </li>
    <li><strong>Results</strong>:
      <ul>
        <li>Best model = <strong>Linear SVM</strong> trained on <strong>vocal_only</strong> data.</li>
        <li>Achieved ~50% performance across all metrics.</li>
      </ul>
    </li>
    <li><strong>Conclusion</strong>:
      <ul>
        <li>Vocal features are sufficient to classify language with strong accuracy.</li>
        <li>Next: expand dataset, apply hyperparameter optimization, and test on external songs.</li>
      </ul>
    </li>
  </ul>
</div>
```

<!--Slide 9 -->
## 
```{=html}
<div style="margin: -50px 40px 0px 40px;">
  <div style="text-align: center; margin-bottom: 16px;">
    <h4>üìä <strong>Research Question 2 ‚Äì Genre Recognition</strong></h4>
  </div>

  <div style="display: flex; gap: 80px; font-size: 20px; line-height: 1.2;">
    <!-- Left Column -->
    <div style="flex: 1;">
      <ul>
        <li><strong>Goal</strong>: Classify songs by <strong>Genre</strong> using audio-derived numerical features.</li>
        <li><strong>Dataset</strong>: Extracted features from 200 tracks, annotated with artist, country, language, and track type.</li>
        <li><strong>Preprocessing</strong>:
          <ul>
            <li>Standardized all numeric features.</li>
            <li>Encoded target variable (genre) with LabelEncoder.</li>
          </ul>
        </li>
        <li><strong>Validation</strong>:
          <ul>
            <li>Applied <strong>Stratified K-Fold (k=5)</strong> cross-validation.</li>
            <li>Used multiple metrics: Accuracy, Precision, Recall, and F1-score.</li>
          </ul>
        </li>
        <li><strong>Hyperparameter Tuning</strong>:
          <ul>
            <li>Performed grid search across different CNN configurations.</li>
            <li>Tuned parameters: convolution filters, kernel size, dropout, and learning rate.</li>
            <li>Selected the combination yielding the best cross-validation performance.</li>
          </ul>
        </li>
      </ul>
    </div>

    <!-- Right Column -->
    <div style="flex: 1;">
      <ul>
        <li><strong>Models</strong>: Knn, Random Forest, CNN.</li>
        <li><strong>Results</strong>:
          <ul>
            <li>Maximum accuracy across models: ~0.60 (Random Forest).</li>
            <li>Precision and F1-scores were generally low, indicating difficulty distinguishing genres.</li>
          </ul>
        </li>
        <li><strong>Interpretation</strong>:
          <ul>
            <li>Models are learning some patterns but struggling with feature overlap between genres.</li>
            <li>Random Forest performs slightly better due to ensemble averaging, but overall results remain modest.</li>
          </ul>
        </li>
        <li><strong>Limitations & Next Steps</strong>:
          <ul>
            <li>Dataset is small; increasing the number of tracks could improve generalization.</li>
            <li>Consider richer feature extraction (e.g., spectrogram-based CNNs) for better genre discrimination.</li>
            <li>Hyperparameter tuning and data augmentation could further boost performance.</li>
          </ul>
        </li>
      </ul>
    </div>
  </div>
</div>


```

<!--Slide 10 -->
## 

```{=html}
<!-- Slide Header -->
<h2 style="text-align: center; font-size: 36px; margin-bottom: 20px;margin-top: -30px">Knn Stats</h2>

<!-- Main Container -->
<div style="display: flex; flex-direction: column; gap: 20px;"> <!-- smaller gap -->

  <!-- Row 1: Graphs Side by Side -->
  <div style="display: flex; flex-direction: row; gap: 10px; justify-content: flex-start;margin-left: -120px">
    <img src="_extra/0_mL_scripts/0_p2/0_knn/hyper_param_sweep.png" 
         alt="Hyperparameter Sweep" style="width: 50%; height: auto;">
    <img src="_extra/0_mL_scripts/0_p2/0_knn/learning_curve.png" 
         alt="Learning Curve Knn" style="width: 50%; height: auto;">
  </div>

  <!-- Row 2: Metrics Table -->
  <div style="border: 2px solid #444; border-radius: 15px; padding: 20px; 
              box-shadow: 2px 2px 10px rgba(0,0,0,0.2); text-align: left; max-width: 800px; margin-top: -10px;">
    <h4 style="font-size: 25px; margin-bottom: 10px;">Metric / Score</h4>
    <table border="0" cellpadding="3" cellspacing="0" style="font-size: 20px;">
      <tr><td>Test Precision (weighted)</td><td>0.1017</td></tr>
      <tr><td>Test F1 Score (weighted)</td><td>0.1117</td></tr>
      <tr><td>LOOCV Accuracy</td><td>0.1350</td></tr>
    </table>
  </div>

</div>
```
<!--Slide 11 -->
## 
```{=html}
<!-- Slide Header -->
<h2 style="text-align: center; font-size: 36px; margin-bottom: 20px;margin-top: -30px">Random Forest Stats</h2>

<!-- Main Container -->
<div style="display: flex; flex-direction: column; gap: 20px;"> <!-- smaller gap -->

  <!-- Row 1: Graphs Side by Side -->
  <div style="display: flex; flex-direction: row; gap: 10px; justify-content: flex-start;margin-left: -120px">
    <img src="_extra\0_mL_scripts\0_p2\0_Random_Forest\RF_HP_Sweep_graph.png" 
         alt="Hyperparameter Sweep" style="width: 50%; height: auto;">
    <img src="_extra\0_mL_scripts\0_p2\0_Random_Forest\RF_LC.png" 
         alt="Learning Curve Random Forest" style="width: 50%; height: auto;">
  </div>

  <!-- Row 2: Metrics Table -->
<div style="border: 2px solid #444; border-radius: 15px; padding: 20px; 
            box-shadow: 2px 2px 10px rgba(0,0,0,0.2); text-align: left; max-width: 800px; margin-top: -10px;">
  <h4 style="font-size: 25px; margin-bottom: 10px;">Metric / Score</h4>
  <table border="1" cellpadding="5" cellspacing="0" style="border-collapse: collapse; font-size: 20px; text-align: left;">
    <thead>
      <tr>
        <th>Metric</th>
        <th>Value</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Accuracy</td>
        <td>0.925</td>
      </tr>
      <tr>
        <td>Precision</td>
        <td>0.927554</td>
      </tr>
      <tr>
        <td>F1 Score</td>
        <td>0.924728</td>
      </tr>
    </tbody>
  </table>
</div>

</div>
```
<!--Slide 12 -->

## 
```{=html}
<!-- Main Container -->
<div style="display: flex; flex-direction: column; gap: 20px;"> <!-- smaller gap -->
<h2 style="text-align: center; font-size: 36px; margin-bottom: 20px;margin-top: -30px">CNN - Grey stats</h2>
  <!-- Row 1: Graphs Side by Side -->
  <div style="display: flex; flex-direction: row; gap: 10px; justify-content: flex-start; margin-left: -120px;">
    <img src="_extra\0_mL_scripts\0_p2\0_grey_Mel_Train\HP_sweep.png" 
         alt="Hyperparameter Sweep" style="width: 50%; height: auto;">
    <img src="_extra\0_mL_scripts\0_p2\0_grey_Mel_Train\lc_grey_.png" 
         alt="Learning Curve CNN Grey" style="width: 50%; height: auto;">
  </div>

  <!-- Row 2: Table + Image Side by Side -->
  <div style="display: flex; flex-direction: row; gap: 30px; align-items: flex-start; justify-content: center; margin-top: -10px;">

    <!-- Metrics Table -->
    <div style="border: 2px solid #444; border-radius: 15px; padding: 20px; 
                box-shadow: 2px 2px 10px rgba(0,0,0,0.2); text-align: left; max-width: 400px;">
      <h4 style="font-size: 25px; margin-bottom: 10px;">Metric / Score</h4>
      <table border="1" cellpadding="5" cellspacing="0" style="border-collapse: collapse; font-size: 20px; text-align: left;">
        <thead>
          <tr>
            <th>Metric</th>
            <th>Value</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>Accuracy</td><td>0.1000</td></tr>
          <tr><td>Precision</td><td>0.0100</td></tr>
          <tr><td>F1 Score</td><td>0.0182</td></tr>
        </tbody>
      </table>
    </div>

    <!-- Image with Caption -->
    <div style="text-align: center;">
      <img src="_extra\0_mL_scripts\0_p2\0_grey_Mel_Train\Queen_We Will Rock You_gray.png" 
           alt="Example Grey Scale Spectrogram" style="max-width: 300px; height: auto; border-radius: 10px; box-shadow: 2px 2px 8px rgba(0,0,0,0.2);">
      <p style="font-size: 16px; margin-top: 8px;">Example Grey-Scale Spectrogram</p>
    </div>

  </div>

</div>
```
<!--Slide 13 -->
## 
```{=html}
<!-- Slide Header -->
<h2 style="text-align: center; font-size: 36px; margin-bottom: 20px; margin-top: -30px;">
  CNN - Color Scale - Stats
</h2>

<!-- Main Container -->
<div style="display: flex; flex-direction: column; gap: 20px;">

  <!-- Row 1: Graphs Side by Side -->
  <div style="display: flex; flex-direction: row; gap: 10px; justify-content: flex-start; margin-left: -120px;">
    <img src="_extra\0_mL_scripts\0_p2\0_col_Mel_Tran\HP_Sweep_Mel_col.png" 
         alt="Hyperparameter Sweep" style="width: 50%; height: auto;">
    <img src="_extra/0_mL_scripts/0_p2/0_knn/learning_curve.png" 
         alt="Learning Curve KNN" style="width: 50%; height: auto;">
  </div>

<!-- Row 2: Metrics Table + Bottom Right Image -->
<div style="display: flex; flex-direction: row; justify-content: space-between; align-items: center; gap: 20px;">

  <!-- Metrics Table -->
  <div style="border: 2px solid #444; border-radius: 15px; padding: 20px; 
              box-shadow: 2px 2px 10px rgba(0,0,0,0.2); text-align: center; max-width: 50%;">
    <h4 style="font-size: 25px; margin-bottom: 20px;">Metric / Score</h4>
    <ul style="list-style: none; display: flex; justify-content: center; gap: 50px; padding: 0; font-size: 20px;">
      <li><strong>Accuracy:</strong> 0.1000</li>
      <li><strong>Precision:</strong> 0.0100</li>
      <li><strong>F1 Score:</strong> 0.0182</li>
    </ul>
  </div>

  <!-- Bottom Right Image with Caption -->
  <div style="text-align: center; width: 40%;">
    <img src="_extra\0_mL_scripts\0_p2\0_grey_Mel_Train\Billie Eilish_bad guy_viridis.png" 
         alt="Bottom Right Graph" style="width: 100%; height: auto;">
    <p style="font-size: 16px; margin-top: -50px;">Example Color-Scale Spectrogram</p>
  </div>

</div>

```
<!--Slide 14 -->

## 
<!-- Q2 Slide Summary -->
<div style="text-align: left; font-size: 30px; line-height: 1.5; margin: 20px;">
  <h3 style="text-align: center; font-size: 40px; margin-bottom: 15px;">üìå Question 2 - Summary</h3>
  <ul>
    <li>Extracted Audio file data.</li>
    <li>Built KNN models and Random Forests models - both performed poorly.</li>
    <li>Built CNN models using grayscale and viridis-scale spectrograms.</li>
    <li>Dataset was small, limiting model performance and generalization.</li>
    <li>Grayscale spectrograms slightly outperformed viridis, but overall accuracy remained low.</li>
    <li>Highlights need for larger datasets and richer audio features for reliable genre recognition.</li>
  </ul>
</div>

<!--Slide 15 -->

## 

<div style="text-align: left; font-size: 30px; line-height: 1.5; margin: 20px;">
  <h3 style="text-align: center; font-size: 40px; margin-bottom: 15px;">Summary of Findings</h3>
  <ul>
    <li>Q1 models - did show trends in reference to Vocal, no Vocal complete song.</li>
    <li>Q2 models - only the viridis spectrogram appears to look like more data may help wiht training.</li>
    <li>Overall extremely low model performance</li>
    <li>Current hypothesis is the data set is too small, we need better features or both</li>
  </ul>
</div>

<!--Slide 16 -->

## 

::: {.banner-container style="margin-bottom: 30px; margin-left: -130px;"}
![](images/banner_mk2.png){.banner-image style="max-width: 100%; height: auto;"}
:::

<!-- Parent container -->

```{=html}
<div style="
    display: flex;
    justify-content: space-between;
    align-items: center; /* vertical center for right image */
    width: 100%;
    height: 500px; /* adjust height as needed */
    position: relative;
    padding: 40px;
    box-sizing: border-box;
    margin-left: -40px;
">

  <!-- LEFT column: top text + bottom logo -->
  <div style="display: flex; flex-direction: column; justify-content: space-between; height: 100%;">
    
    <!-- TOP LEFT: Text block -->
    <div style="text-align: left;">
      <h3>Thank you for listening</h3>
      <ul style="font-size: 35px; margin-top: 20px;">
        <li>Your attention was appreciated.</li>
        <li>Questions welcome.</li>
      </ul>
      <p>Team Members:</p>
    </div>

    <!-- BOTTOM LEFT: Logo -->
    <div style="
        display: inline-block;
        padding: 4px;
        margin-top: -30px;
        margin-right: 150px;
        margin-left: -50px;
    ">
      <img src="images/audio_phile_logo_mk2.png" alt="AudioPhile Logo" style="height: 180px;">
    </div>
    
  </div>

  <!-- RIGHT column: vertical-centered GIF -->
  <div style="display: flex; align-items: center;margin-left: 10px;margin-right: -80px">
    <img src="images/rotating_cube_signal_4.gif" alt="Rotating Cube" style="height: 300px;">
  </div>

</div>
```