---
title: ""
subtitle: ""
author: ""
title-slide-attributes:
  data-background-image: ""
  data-background-size: ""
  data-background-opacity: ""
  data-slide-number: true
footer: |
  <div style="
    position: relative;
    bottom: -10px;
    left: 650px;
    right: 0;
    height: 50px;
    background: rgba(255, 255, 255, 0.8);
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 0 24px 0 40px;
    z-index: 9999;
    box-sizing: border-box;
    margin-top: 200px; /* adjust to push it further down */
  ">   
    <span style="position: relative; font-size: 2em; padding-right: 500px;margin-top: -30px">Wednesday-August-20-2025</span>
    <img src="images/audio_chrome_5.png" height="80" style="vertical-align: middle;margin-top: -10px;" />
  </div>  
format:
  revealjs:
    theme:  ['data/customtheming.scss']
    css: slide_styles.css
    slide-number: true
editor: visual
jupyter: python3
execute:
  echo: false
---

```{python}
#| label: load-packages
#| include: false

# Load packages here
import pandas as pd
import seaborn as sns

```

```{python}
#| label: setup
#| include: false
#| 
# Set up plot theme and figure resolution
sns.set_theme(style="whitegrid")
sns.set_context("notebook", font_scale=1.1)

import matplotlib.pyplot as plt
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['figure.figsize'] = (6, 6 * 0.618)
```

::: {.banner-container style="margin-bottom: 30px;"}
![](images/banner_mk2.png){.banner-image style="max-width: 100%; height: auto;"}
:::

```{=html}
<!-- Parent Container -->
<div style="display: flex; justify-content: space-between; align-items: flex-start; width: 100%; padding: 40px; box-sizing: border-box;">

  <!-- LEFT column: Image + Audiophiles block -->
  <div style="display: flex; flex-direction: column; align-items: flex-start; margin-right: 20px; transform: translate(-60px, -20px);">
    <!-- Image -->
    <div style="margin-bottom: 10px; margin-left: 40px;">
      <img src="images/DS_group_mk5.png" alt="Water Drop" style="height: 300px;" />
    </div>
    <!-- Audiophiles block -->
    <div style="
      display: flex;
      align-items: center;
      border: 1px solid black;
      border-radius: 12px;
      padding: 10px 16px;
      background-color: #fff;
      width: 380px;
    ">
      <img src="images/head_phones.png" alt="Logo" style="height: 120px; margin-right: 16px;" />
      <span style="
        font-size: 22px;
        font-family: Arial, sans-serif;
        color: #333;
      ">
        <strong>The AudioPhiles:</strong><br> Nathan Herling<br> & Yashi Mi
      </span>
    </div>
  </div>

  <!-- RIGHT column: Title + course info -->
  <div style="display: flex; flex-direction: column; justify-content: flex-start; height: 300px; text-align: right;">
    <!-- Title block -->
    <div style="
      font-size: 70px;
      font-weight: bold;
      font-family: Arial, sans-serif;
      text-align: left;
      line-height: 1.4;
      color: #1B9FAB;
      margin-bottom: 20px;
    ">
      Audio Alchemy:<br>
      Decoding Sound for Smarter UX
    </div>

    <!-- INFO 523 block -->
    <div style="
      font-size: 30px;
      color: #AB0520;
      border: 3px solid #AB0520;
      border-radius: 16px;
      padding: 16px 24px;
      background-color: #fff5f7;
      box-shadow: 0 4px 10px rgba(171, 5, 32, 0.2);
      display: inline-block;
      margin-top: 0px;
      width: 100%;
    ">
      INFO 523 ‚Äî Summer 2025 - Final Project
    </div>
  </div>

</div>
```

<!--Slide 2 -->

## 

```{=html}
<div style="margin: -20px auto; border: 2px solid #ccc; border-radius: 10px; padding: 12px 20px; background-color: #fdfdfd; font-size: 0.60em; line-height: 1.3; max-width: 110%;">

  <h3 style="color:#007ACC; margin: 0 0 4px;">üéØ Project Description & Goals</h3>
  <p style="margin: 0 0 4px;">Our team is developing a machine learning system for an AI-driven music recommendation service.<br>The main goals are:</p>
  <ul style="margin: 0 0 4px 16px; padding-left: 0; list-style-position: outside;">
    <li style="margin: 0;">Build a model capable of recognizing the language(s) spoken in audio files.</li>
    <li style="margin: 0;">Assess whether new songs align with a user‚Äôs musical preferences.</li>
  </ul>

  <hr style="margin: 6px 0; border: none; border-top: 1px solid #ddd;">

  <h3 style="color:#32CD32; margin: 0 0 4px;">‚ùì Research Question 1 ‚Äì Language Recognition</h3>
  <p style="margin: 0 0 4px;"><strong>How can we leverage statistical and time-frequency features from separated vocal and audio tracks to build effective language recognition models?</strong></p>
  <ul style="margin: 0 0 4px 16px; padding-left: 0; list-style-position: outside;">
    <li style="margin: 0;">What are the strengths and limitations of classical models (e.g., SVMs, Random Forest, Logistic Regression)?</li>
    <li style="margin: 0;">How do feature engineering and validation improve model robustness?</li>
  </ul>

  <hr style="margin: 6px 0; border: none; border-top: 1px solid #ddd;">

  <h3 style="color:#32CD32; margin: 0 0 4px;">‚ùì Research Question 2 ‚Äì Recommendation System [Genre Recognition]</h3>
  <p style="margin: 0 0 4px;"><strong>Starting with genre recognition as part of the user UI/UX, can a user‚Äôs preferred genres be learned through feature analysis of audio files?</strong></p>
  <ul style="margin: 0 0 0 16px; padding-left: 0; list-style-position: outside;">
    <li style="margin: 0;">Using classical supervised models: Can audio features be extracted and models trained to recognize a user's preferred genres?</li>
    <li style="margin: 0;">Using frequency/time heatmap image extraction: Are classical models capable of determining musical genres?</li>
  </ul>

</div>
```

<!--Slide 3-->

## 

```{=html}
<div style="font-family: Arial, sans-serif; font-size: 0.75em; line-height: 1.4; width: 100%; margin: -10px auto 20px auto; padding: 16px; border: 1.5px solid #ccc; border-radius: 8px; background-color: #f9f9f9;">
  <h3 style="color: #007ACC; margin-bottom: 12px; text-align: center;">Data Files and Extraction Workflow</h3>
  <ul style="padding-left: 20px; color: #333; margin: 0;">
    <li><strong>User Input:</strong> Initial CSV files containing song names; optionally including genre, language, and artist information.</li>
    <li><strong>Data Completion:</strong> Automated web scraping to fill missing metadata fields such as genre, language, and artist.</li>
    <li><strong>YouTube Integration:</strong> Web scraping YouTube to find matching song links, then storing these links and related metadata in a JSON file.</li>
    <li><strong>Audio Acquisition:</strong> Downloading .wav audio files from YouTube links for each song.</li>
    <li><strong>Feature Extraction:</strong> Using Python scripts to analyze audio files and extract features (e.g., fundamental frequency, MFCCs, tempo).</li>
    <li><strong>Output Files:</strong> Extracted audio features are saved into CSV files; visualizations like spectrograms are saved as PNG images.</li>
  </ul>
</div>
```

<!--Slide 4 -->

## 

:::: cell
::: {style="max-width: 100%; margin: 0 -80px 0 -80px; font-family: Arial, sans-serif; font-size: 0.65em; line-height: 1.2; border: 1.5px solid #ccc; border-radius: 8px; padding: 8px 12px; background-color: #fdfdfd; overflow-x: auto;"}
<h2 style="color: #007ACC; margin: 0 0 8px 0; text-align: center; font-size: 1.2em;">

Feature Scraping

</h2>

+--------------------+---------------------------------------------------------------------------------------+
| Feature            | Description                                                                           |
+====================+=======================================================================================+
| fundamental_freq   | Fundamental frequency (mean pitch via librosa.pyin)                                   |
+--------------------+---------------------------------------------------------------------------------------+
| freq_e_1           | Dominant spectral energy #1 (highest energy frequency bin)                            |
+--------------------+---------------------------------------------------------------------------------------+
| freq_e_2           | Dominant spectral energy #2 (2nd highest energy frequency bin)                        |
+--------------------+---------------------------------------------------------------------------------------+
| freq_e_3           | Dominant spectral energy #3 (3rd highest energy frequency bin)                        |
+--------------------+---------------------------------------------------------------------------------------+
| key                | Estimated musical key (C, C#, D, ..., B) via chroma features                          |
+--------------------+---------------------------------------------------------------------------------------+
| duration           | Length of audio in seconds                                                            |
+--------------------+---------------------------------------------------------------------------------------+
| zero_crossing_rate | Average zero crossing rate (signal sign changes)                                      |
+--------------------+---------------------------------------------------------------------------------------+
| mfcc_mean          | Mean of 13 MFCC coefficients (timbre features)                                        |
+--------------------+---------------------------------------------------------------------------------------+
| mfcc_std           | Standard deviation of MFCC coefficients                                               |
+--------------------+---------------------------------------------------------------------------------------+
| tempo              | Estimated tempo in beats per minute (BPM)                                             |
+--------------------+---------------------------------------------------------------------------------------+
| rms_energy         | Root mean square energy (loudness measure)                                            |
+--------------------+---------------------------------------------------------------------------------------+
| track_type         | Audio track type (0=full mix, 1=vocal only, 2=no vocals)                              |
+--------------------+---------------------------------------------------------------------------------------+
| mel_spectrogram    | Mel-scaled spectrogram representing frequency content over time (human hearing range) |
+--------------------+---------------------------------------------------------------------------------------+
:::
::::

------------------------------------------------------------------------

<!--Slide 5 -->

#### **Research Question 1 ‚Äì Language Recognition**

-   <span style="font-size:30px">**Goal**: Classify songs by **language** using audio-derived numerical features.
-   <span style="font-size:30px">**Dataset**: Extracted features from \~120 tracks, annotated with artist, country, language, and track type.
-   <span style="font-size:30px">**Preprocessing**:
    -   <span style="font-size:30px">Standardized all numeric featuresquarto render presentation.qmd.

    -   <span style="font-size:30px">Encoded target variable (language) with LabelEncoder.
-   <span style="font-size:30px">**Validation**:
    -   <span style="font-size:30px">Applied **Stratified K-Fold (k=5)** cross-validation.

    -   <span style="font-size:30px">Used multiple metrics: Accuracy, Precision, Recall, and F1-score.
-   <span style="font-size:30px">**Models**: Logistic Regression, Random Forest, and Linear SVM.

------------------------------------------------------------------------

<!--Slide 6 -->

#### Evaluation Results

+---------------------+--------------------+----------------+-----------------+--------------+--------------+
| ##### Ablation      | ##### Model        | ##### Accuracy | ##### Precision | ##### Recall | ##### **F1** |
+:====================+:===================+===============:+================:+=============:+=============:+
| ##### complete_song | ##### LogReg       | ##### 0.399    | ##### 0.398     | ##### 0.447  | ##### 0.387  |
+---------------------+--------------------+----------------+-----------------+--------------+--------------+
| ##### complete_song | ##### RandomForest | ##### 0.626    | ##### 0.469     | ##### 0.410  | ##### 0.401  |
+---------------------+--------------------+----------------+-----------------+--------------+--------------+
| ##### complete_song | ##### SVM_linear   | ##### 0.432    | ##### 0.443     | ##### 0.504  | ##### 0.427  |
+---------------------+--------------------+----------------+-----------------+--------------+--------------+
| ##### vocal_only    | ##### LogReg       | ##### 0.560    | ##### 0.531     | ##### 0.567  | ##### 0.509  |
+---------------------+--------------------+----------------+-----------------+--------------+--------------+
| ##### vocal_only    | ##### RandomForest | ##### 0.552    | ##### 0.426     | ##### 0.404  | ##### 0.385  |
+---------------------+--------------------+----------------+-----------------+--------------+--------------+
| ##### vocal_only    | ##### SVM_linear   | ##### 0.544    | ##### 0.542     | ##### 0.583  | ##### 0.514  |
+---------------------+--------------------+----------------+-----------------+--------------+--------------+
| ##### no_vocal      | ##### LogReg       | ##### 0.333    | ##### 0.371     | ##### 0.364  | ##### 0.316  |
+---------------------+--------------------+----------------+-----------------+--------------+--------------+
| ##### no_vocal      | ##### RandomForest | ##### 0.577    | ##### 0.436     | ##### 0.349  | ##### 0.328  |
+---------------------+--------------------+----------------+-----------------+--------------+--------------+
| ##### no_vocal      | ##### SVM_linear   | ##### 0.366    | ##### 0.418     | ##### 0.411  | ##### 0.347  |
+---------------------+--------------------+----------------+-----------------+--------------+--------------+

<!--Slide 7 -->

## Learning Curve (F1 Score)

```{python}
#| echo: false
#| fig-cap: "F1 (macro) comparison across ablations and models"
#| fig-width: 7
#| fig-height: 4
#| out-width: 70%
#| fig-align: center
#| fig-format: svg

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
data = [ {"ablation": "complete_song", "model": "LogReg", "f1": 0.387},
{"ablation": "complete_song", "model": "RandomForest", "f1": 0.401},
{"ablation": "complete_song", "model": "SVM_linear", "f1": 0.427},
{"ablation": "vocal_only", "model": "LogReg", "f1": 0.509},
{"ablation": "vocal_only", "model": "RandomForest", "f1": 0.385},
{"ablation": "vocal_only", "model": "SVM_linear", "f1": 0.514},
{"ablation": "no_vocal", "model": "LogReg", "f1": 0.316},
{"ablation": "no_vocal", "model": "RandomForest", "f1": 0.328},
{"ablation": "no_vocal", "model": "SVM_linear", "f1": 0.347}]
df_f1 = pd.DataFrame(data)
order_ablation = ["vocal_only", "complete_song", "no_vocal"]
order_model = ["SVM_linear", "LogReg", "RandomForest"]
df_f1["ablation"] = pd.Categorical(df_f1["ablation"], categories=order_ablation, ordered=True)
df_f1["model"] = pd.Categorical(df_f1["model"], categories=order_model, ordered=True)
plt.figure(figsize=(8,4))
ax = sns.barplot(data=df_f1, x="ablation", y="f1", hue="model")
ax.set_xlabel("Track Type (Ablation)")
ax.set_ylabel("F1 (macro)")
ax.set_title("F1 (macro) by Track Type and Model")
plt.show()
```

<!--Slide 8 -->

## Question 1-Summary

-   <span style="font-size:30px">**What we did**:

    -   <span style="font-size:30px">Designed a supervised ML pipeline with feature scaling, label encoding, stratified CV.

    -   <span style="font-size:30px">Evaluated three classifiers on different track-type subsets.

-   <span style="font-size:30px">**Results**:

    -   <span style="font-size:30px">Best model = **Linear SVM** trained on **vocal_only** data.

    -   <span style="font-size:30px">Achieved \~80% performance across all metrics.

-   <span style="font-size:30px">**Conclusion**:

    -   <span style="font-size:30px">Vocal features are sufficient to classify language with strong accuracy.

    -   <span style="font-size:30px">Next: expand dataset, apply hyperparameter optimization, and test on external songs.

<!--Slide 9 -->

## 

Q2 Overview - Nathan describe your question and how you implemented mL \[libraries, validation\]

<!--Slide 10 -->

## 

Q2 Results \[1/3\] - Nathan graphs? Learning Curve, ROC, any hyperparameter optimization?

<!--Slide 11 -->

## 

Q2 Results \[2/3\] - Nathan Results (% scores) Validation methods.

<!--Slide 12 -->

## 

Q2 Results \[3/3\] - Nathan. Summarize - what you did/results.

<!--Slide 13 -->

## 

Q2 Summary - Nathan

<!--Slide 14 -->

## 

Full Summary - Nathan talk about both question findings.

<!--Slide 15 -->

## 

In Closing - Nathan