---
title: ""
subtitle: ""
author: ""
title-slide-attributes:
  data-background-image: ""
  data-background-size: ""
  data-background-opacity: ""
  data-slide-number: true
footer: |
  <div style="
    position: relative;
    bottom: -10px;
    left: 650px;
    right: 0;
    height: 50px;
    background: rgba(255, 255, 255, 0.8);
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 0 24px 0 40px;
    z-index: 9999;
    box-sizing: border-box;
    margin-top: 200px; /* adjust to push it further down */
  ">   
    <span style="position: relative; font-size: 2em; padding-right: 500px;margin-top: -30px">Wednesday-August-20-2025</span>
    <img src="images/audio_chrome_5.png" height="80" style="vertical-align: middle;margin-top: -10px;" />
  </div>  
format:
  revealjs:
    theme:  ['data/customtheming.scss']
    css: slide_styles.css
    slide-number: true
editor: visual
jupyter: python3
execute:
  echo: false
---

```{python}
#| label: load-packages
#| include: false

# Load packages here
import pandas as pd
import seaborn as sns

```

```{python}
#| label: setup
#| include: false
#| 
# Set up plot theme and figure resolution
sns.set_theme(style="whitegrid")
sns.set_context("notebook", font_scale=1.1)

import matplotlib.pyplot as plt
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['figure.figsize'] = (6, 6 * 0.618)
```

::: {.banner-container style="margin-bottom: 30px; margin-left: -130px;"}
![](images/banner_mk2.png){.banner-image style="max-width: 100%; height: auto;"}
:::

```{=html}
<!-- Parent Container -->
<div style="display: flex; justify-content: space-between; align-items: flex-start; width: 100%; padding: 40px; box-sizing: border-box;">

  <!-- LEFT column: Image + Audiophiles block -->
  <div style="display: flex; flex-direction: column; align-items: flex-start; margin-right: 20px; transform: translate(-60px, -20px);">
    <!-- Image -->
    <div style="margin-bottom: 10px; margin-left: 40px;">
      <img src="images/DS_group_mk5.png" alt="Water Drop" style="height: 300px;" />
    </div>
    <!-- Audiophiles block -->
    <div style="
      display: flex;
      align-items: center;
      border: 1px solid white;
      border-radius: 12px;
      padding: 10px 10px;
      background-color: #fff;
      width: 380px;
    ">
      <img src="images/audio_phile_logo_mk2.png" alt="Logo" style="height: 160px; margin-right: 0px;" />
    </div>
  </div>

  <!-- RIGHT column: Title + course info -->
  <div style="display: flex; flex-direction: column; justify-content: flex-start; height: 300px; text-align: right;">
    <!-- Title block -->
    <div style="
      font-size: 70px;
      font-weight: bold;
      font-family: Arial, sans-serif;
      text-align: left;
      line-height: 1.4;
      color: #1B9FAB;
      margin-bottom: 20px;
    ">
      Audio Alchemy:<br>
      Decoding Sound for Smarter UX
    </div>

    <!-- INFO 523 block -->
    <div style="
      font-size: 30px;
      color: #AB0520;
      border: 3px solid #AB0520;
      border-radius: 16px;
      padding: 16px 24px;
      background-color: #fff5f7;
      box-shadow: 0 4px 10px rgba(171, 5, 32, 0.2);
      display: inline-block;
      margin-top: 0px;
      width: 100%;
    ">
      INFO 523 ‚Äî Summer 2025 - Final Project
    </div>
  </div>

</div>
```

<!--Slide 2 -->

## 

```{=html}
<div style="margin: -20px -60px -80px -80px; border: 5px solid midnightblue; border-radius: 10px; padding: 12px 20px; background-color: #fdfdfd; font-size: 0.60em; line-height: 1.3; width: 110%;">


  <h3 style="color:#007ACC; margin: 0 0 4px;">ü§ñ Project Description & Goals</h3>
<p style="margin: 0 0 4px; font-weight: bold;">
  Our team is developing a machine learning system for an AI-driven music recommendation service.<br>
  The main goals are:
</p>
  <ul style="margin: 0 0 4px 16px; padding-left: 0; list-style-position: outside;">
    <li style="margin: 0;">Build a model capable of recognizing the language(s) spoken in audio files.</li>
    <li style="margin: 0;">Assess whether new songs align with a user‚Äôs musical preferences.</li>
  </ul>

  <hr style="margin: 6px 0; border: none; border-top: 2px solid #aaa;">

  <h3 style="color:#32CD32; margin: 0 0 4px;">‚ú¶ Question 1 ‚Äì Language Recognition</h3>
  <p style="margin: 0 0 4px;font-weight: bold;"><strong>How can we leverage statistical and time-frequency features from separated vocal and audio tracks to build effective language recognition models?</strong></p>
  <ul style="margin: 0 0 4px 16px; padding-left: 0; list-style-position: outside;">
    <li style="margin: 0;">What are the strengths and limitations of classical models (e.g., SVMs, Random Forest, Logistic Regression)?</li>
    <li style="margin: 0;">How do feature engineering and validation improve model robustness?</li>
  </ul>

  <hr style="margin: 6px 0; border: none; border-top: 2px solid #aaa;">

  <h3 style="color:#32CD32; margin: 0 0 4px;">‚ú¶ Question 2 ‚Äì Recommendation System [Genre Recognition]</h3>
  <p style="margin: 0 0 4px;font-weight: bold;"><strong>Starting with genre recognition as part of the user UI/UX, can a user‚Äôs preferred genres be learned through feature analysis of audio files?</strong></p>
  <ul style="margin: 0 0 0 16px; padding-left: 0; list-style-position: outside;">
    <li style="margin: 0;">Using classical supervised models: Can audio features be extracted and models trained to recognize a user's preferred genres?</li>
    <li style="margin: 0;">Using frequency/time heatmap image extraction: Are classical models capable of determining musical genres from spectrogram-like representations?</li>
  </ul>

</div>
```

<!--Slide 3-->

## 

```{=html}
<div style="margin: -20px -60px -80px -80px; border: 5px solid midnightblue; border-radius: 10px; padding: 12px 20px; background-color: #fdfdfd; font-size: 0.75em; line-height: 1.3; width: 110%;">

  <h3 style="color: #007ACC; margin-bottom: 12px; text-align: center;">üß© Data Files and Extraction Workflow</h3>
  <ul style="padding-left: 20px; color: #333; margin: 0;">
    <li><strong>User Input:</strong> Providing initial <code>CSV</code> files containing song names, optionally including genre, language, and artist information.</li>
    <li><strong>Data Completion:</strong> Performing automated web scraping with <code>Python</code> scripts, filling in missing metadata fields such as genre, language, and artist.</li>
    <li><strong>YouTube Integration:</strong> Scraping YouTube with <code>Python</code> scripts, finding matching song <code>URLs</code>, and storing these links and related metadata in a <code>JSON</code> file.</li>
    <li><strong>Audio Acquisition:</strong> Downloading <code>.wav</code> audio files from YouTube <code>URLs</code> for each song with <code>Python</code> scripts.</li>
    <li><strong>Feature Extraction:</strong> Using <code>Python</code> (<code>numpy</code> and <code>librosa</code> libraries) scripts for analyzing audio files and extracting features (e.g., fundamental frequency, MFCCs, tempo).</li>
    <li><strong>Output Files:</strong> Saving extracted audio features as <code>CSV</code> files; saving visualizations such as spectrograms as <code>.png</code> images. From here, constructing machine learning pipelines with <code>Python</code> libraries.</li>
  </ul>
</div>
```

<!--Slide 4 -->

## 

:::: cell
::: {style="width: 125%; margin: -40px -140px 30px -160px; font-family: Arial, sans-serif; font-size: 0.65em; line-height: 1.2; border: 5px solid midnightblue; border-radius: 8px; padding: 8px 12px; background-color: #fdfdfd; overflow-x: auto;"}
<h2 style="color: #007ACC; margin: -10px 0 -10px 0; text-align: center; font-size: 2.0em;">

üîç Feature Scraping

</h2>

| Feature | Description |
|-----------------|-------------------------------------------------------|
| fundamental_freq | Fundamental frequency (mean pitch via librosa.pyin) |
| freq_e_1 | Dominant spectral energy #1 (highest energy frequency bin) |
| freq_e_2 | Dominant spectral energy #2 (2nd highest energy frequency bin) |
| freq_e_3 | Dominant spectral energy #3 (3rd highest energy frequency bin) |
| key | Estimated musical key (C, C#, D, ..., B) via chroma features |
| duration | Length of audio in seconds |
| zero_crossing_rate | Average zero crossing rate (signal sign changes) |
| mfcc_mean | Mean of 13 MFCC coefficients (timbre features) |
| mfcc_std | Standard deviation of MFCC coefficients |
| tempo | Estimated tempo in beats per minute (BPM) |
| rms_energy | Root mean square energy (loudness measure) |
| track_type | Audio track type (0=full mix, 1=vocal only, 2=no vocals) |
| mel_spectrogram | Mel-scaled spectrogram representing frequency content over time (human hearing range) |
:::
::::

------------------------------------------------------------------------

<!--Slide 5 -->

```{=html}
<div>
  <div style="text-align: center; margin-bottom: 16px;">
    <h4>üìä <strong>Research Question 1 ‚Äì Language Recognition</strong></h4>
  </div>

  <div style="font-size: 30px; line-height: 1.4;">
    <ul>
      <li><strong>Goal</strong>: Classify songs by <strong>language</strong> using audio-derived numerical features.</li>
      <li><strong>Dataset</strong>: Extracted features from ~120 tracks, annotated with artist, country, language, and track type.</li>
      <li><strong>Preprocessing</strong>:
        <ul>
          <li>Standardized all numeric features.</li>
          <li>Encoded target variable (language) with LabelEncoder.</li>
        </ul>
      </li>
      <li><strong>Validation</strong>:
        <ul>
          <li>Applied <strong>Stratified K-Fold (k=5)</strong> cross-validation.</li>
          <li>Used multiple metrics: Accuracy, Precision, Recall, and F1-score.</li>
        </ul>
      </li>
      <li><strong>Models</strong>: Logistic Regression, Random Forest, and Linear SVM.</li>
    </ul>
  </div>
</div>
```

------------------------------------------------------------------------

<!--Slide 6 -->

::: {style="text-align: center; margin-bottom: 12px;"}
<h4>Evaluation Results</h4>
:::

:::: cell
::: {style="width: 120%; margin: 20px -140px 30px -120px; font-family: Arial, sans-serif; font-size: 0.65em; line-height: 1.2; border: 2px solid midnightblue; border-radius: 8px; padding: 8px 12px; background-color: #fdfdfd; overflow-x: auto;"}
<h2 style="color: #007ACC; margin: 0 0 8px 0; text-align: center; font-size: 1.2em;">

Model Performance ‚Äì Ablation Study

</h2>

| Ablation       | Model        | Accuracy | Precision | Recall | F1    |
|----------------|--------------|----------|-----------|--------|-------|
| complete_song  | LogReg       | 0.399    | 0.398     | 0.447  | 0.387 |
| complete_song  | RandomForest | 0.626    | 0.469     | 0.410  | 0.401 |
| complete_song  | SVM_linear   | 0.432    | 0.443     | 0.504  | 0.427 |
| vocal_only     | LogReg       | 0.560    | 0.531     | 0.567  | 0.509 |
| vocal_only     | RandomForest | 0.552    | 0.426     | 0.404  | 0.385 |
| vocal_only     | SVM_linear   | 0.544    | 0.542     | 0.583  | 0.514 |
| no_vocal       | LogReg       | 0.333    | 0.371     | 0.364  | 0.316 |
| no_vocal       | RandomForest | 0.577    | 0.436     | 0.349  | 0.328 |
| no_vocal       | SVM_linear   | 0.366    | 0.418     | 0.411  | 0.347 |
| **Column Min** | \-           | 0.333    | 0.371     | 0.349  | 0.316 |
| **Column Max** | \-           | 0.626    | 0.542     | 0.583  | 0.514 |
:::
::::

## <!--Slide 7 -->

::: {style="text-align: center; margin-top: -40px; margin-right: 10px; margin-bottom: 30px; margin-left: 5px;"}
<h4>F1 (macro) comparison across ablations and models</h4>
:::

```{python}
#| echo: false
#| fig-cap: ""
#| fig-width: 7
#| fig-height: 4
#| out-width: 70%
#| fig-align: center
#| fig-format: svg

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
data = [ {"ablation": "complete_song", "model": "LogReg", "f1": 0.387},
{"ablation": "complete_song", "model": "RandomForest", "f1": 0.401},
{"ablation": "complete_song", "model": "SVM_linear", "f1": 0.427},
{"ablation": "vocal_only", "model": "LogReg", "f1": 0.509},
{"ablation": "vocal_only", "model": "RandomForest", "f1": 0.385},
{"ablation": "vocal_only", "model": "SVM_linear", "f1": 0.514},
{"ablation": "no_vocal", "model": "LogReg", "f1": 0.316},
{"ablation": "no_vocal", "model": "RandomForest", "f1": 0.328},
{"ablation": "no_vocal", "model": "SVM_linear", "f1": 0.347}]
df_f1 = pd.DataFrame(data)
order_ablation = ["vocal_only", "complete_song", "no_vocal"]
order_model = ["SVM_linear", "LogReg", "RandomForest"]
df_f1["ablation"] = pd.Categorical(df_f1["ablation"], categories=order_ablation, ordered=True)
df_f1["model"] = pd.Categorical(df_f1["model"], categories=order_model, ordered=True)
plt.figure(figsize=(8,4))
ax = sns.barplot(data=df_f1, x="ablation", y="f1", hue="model")
ax.set_xlabel("Track Type (Ablation)")
ax.set_ylabel("F1 (macro)")
ax.set_title("F1 (macro) by Track Type and Model")
plt.show()
```

<!--Slide 8 -->

## üìå Question 1-Summary

```{=html}
<div style="font-size: 30px; line-height: 1.4;">
  <ul>
    <li><strong>What we did</strong>:
      <ul>
        <li>Designed a supervised ML pipeline with feature scaling, label encoding, stratified CV.</li>
        <li>Evaluated three classifiers on different track-type subsets.</li>
      </ul>
    </li>
    <li><strong>Results</strong>:
      <ul>
        <li>Best model = <strong>Linear SVM</strong> trained on <strong>vocal_only</strong> data.</li>
        <li>Achieved ~50% performance across all metrics.</li>
      </ul>
    </li>
    <li><strong>Conclusion</strong>:
      <ul>
        <li>Vocal features are sufficient to classify language with strong accuracy.</li>
        <li>Next: expand dataset, apply hyperparameter optimization, and test on external songs.</li>
      </ul>
    </li>
  </ul>
</div>
```

<!--Slide 9 -->

## 

Q2 (A/B) Overview - Nathan describe your question and how you implemented mL \[libraries, validation\]

<!--Slide 10 -->

## 

Q2 (A) Results - Nathan graphs? Learning Curve, ROC, any hyperparameter optimization?

<!--Slide 11 -->

## 

Q2 (A) Results - Nathan Results (% scores) Validation methods.

<!--Slide 12 -->

## 

Q2 (B) Results - Nathan. Summarize - what you did/results.

<!--Slide 13 -->

## 

Q2 (B) Results \[3/3\] - Nathan. Summarize - what you did/results.

<!--Slide 14 -->

## 

Q2 Summary - Nathan

<!--Slide 15 -->

## 

Full Summary - Nathan talk about both question findings.

<!--Slide 16 -->

## 

::: {.banner-container style="margin-bottom: 30px; margin-left: -130px;"}
![](images/banner_mk2.png){.banner-image style="max-width: 100%; height: auto;"}
:::

<!-- Parent container -->

```{=html}
<div style="
    display: flex;
    justify-content: space-between;
    align-items: center; /* vertical center for right image */
    width: 100%;
    height: 500px; /* adjust height as needed */
    position: relative;
    padding: 40px;
    box-sizing: border-box;
    margin-left: -40px;
">

  <!-- LEFT column: top text + bottom logo -->
  <div style="display: flex; flex-direction: column; justify-content: space-between; height: 100%;">
    
    <!-- TOP LEFT: Text block -->
    <div style="text-align: left;">
      <h3>Thank you for listening</h3>
      <ul style="font-size: 35px; margin-top: 20px;">
        <li>Your attention was appreciated.</li>
        <li>Questions welcome.</li>
      </ul>
      <p>Team Members:</p>
    </div>

    <!-- BOTTOM LEFT: Logo -->
    <div style="
        display: inline-block;
        padding: 4px;
        margin-top: -30px;
        margin-right: 150px;
        margin-left: -50px;
    ">
      <img src="images/audio_phile_logo_mk2.png" alt="AudioPhile Logo" style="height: 180px;">
    </div>
    
  </div>

  <!-- RIGHT column: vertical-centered GIF -->
  <div style="display: flex; align-items: center;margin-left: 10px;margin-right: -80px">
    <img src="images/rotating_cube_signal_4.gif" alt="Rotating Cube" style="height: 300px;">
  </div>

</div>
```